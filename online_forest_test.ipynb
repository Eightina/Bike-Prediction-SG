{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('lonal_entro.csv')\n",
    "model_1=RandomForestRegressor(random_state=1)\n",
    "model_2a=RandomForestRegressor(random_state=1)\n",
    "model_2b=RandomForestRegressor(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datax=pd.read_csv('0_removed.csv')\n",
    "trip=datax['trip_m6_wd_pm']\n",
    "bins=[-0.1,0.5,5000]\n",
    "cut_res=pd.cut(trip,bins=bins,labels=[0,1])\n",
    "data['has_trip']=cut_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol='has_trip'\n",
    "xcol=[ 'ori', 'dst','dist_km','fsize_m6_wd_pm','community_m6','mrt_km_o',\n",
    "'far_hdb_o', 'far_priv_o', 'far_comm_o', 'mrt_km_d',\n",
    "'far_hdb_d', 'far_priv_d', 'far_comm_d', 'smooth_entro_o',\n",
    "       'smooth_entro_d','ori_lat', 'ori_lon', 'dst_lat', 'dst_lon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data[ycol]\n",
    "X=data[xcol]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)\n",
    "model_2a.fit(X=X_train,y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "od01_pred=model_2a.predict(X_test)\n",
    "r2=r2_score(y_pred=od01_pred,y_true=y_test)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss=mean_squared_error(y_pred=od01_pred,y_true=y_test)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以发现，随机森林能够非常好地对发生出行的od对进行预测\n",
    "再尝试直接对需求进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol1='trip_m6_wd_pm'\n",
    "xcol1=[ 'ori', 'dst','dist_km','fsize_m6_wd_pm','community_m6','mrt_km_o',\n",
    "'far_hdb_o', 'far_priv_o', 'far_comm_o', 'mrt_km_d',\n",
    "'far_hdb_d', 'far_priv_d', 'far_comm_d', 'smooth_entro_o',\n",
    "       'smooth_entro_d','ori_lat', 'ori_lon', 'dst_lat', 'dst_lon']\n",
    "y1=data[ycol1]\n",
    "X1=data[xcol1]\n",
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(X1,y1,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(X=X_train1,y=y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_pred=model_1.predict(X_test1)\n",
    "r2=r2_score(y_pred=trip_pred,y_true=y_test1)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss2=mean_squared_error(y_pred=trip_pred,y_true=y_test1)\n",
    "loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol2='trip_m6_wd_pm'\n",
    "xcol2=[ 'ori', 'dst','dist_km','fsize_m6_wd_pm','community_m6','mrt_km_o',\n",
    "'far_hdb_o', 'far_priv_o', 'far_comm_o', 'mrt_km_d',\n",
    "'far_hdb_d', 'far_priv_d', 'far_comm_d', 'smooth_entro_o',\n",
    "       'smooth_entro_d','ori_lat', 'ori_lon', 'dst_lat', 'dst_lon']\n",
    "y2a=data[ycol2]\n",
    "y2b=data['has_trip']\n",
    "X2=data[xcol2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1_val=model_1.predict(X2)\n",
    "layer2_val=model_2a.predict(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2=r2_score(y_pred=layer1_val,y_true=y2a)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=layer1_val*layer2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr2=r2_score(y_pred=final,y_true=y2a)\n",
    "nr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "两层分层预测不是个好主意。随机性太强了，看fetures.ipynb的分组箱图。下面看看pc4的效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('lonal_entro.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ycol='trip_m6_wd_pm'\n",
    "xcol1=['community_m6','far_comm_d','far_hdb_d','far_hdb_o','far_comm_o',\n",
    "'smooth_entro_o','smooth_entro_d','ori','dst','dist_km','community_m6',\n",
    "'mrt_km_d']\n",
    "xcol2=['community_m6','far_comm_d','far_hdb_d','far_hdb_o','far_comm_o',\n",
    "'smooth_entro_o','smooth_entro_d','od_lonal_pc4','dist_km','community_m6',\n",
    "'mrt_km_d']\n",
    "xcol3=['community_m6','far_comm_d','far_hdb_d','far_hdb_o','far_comm_o',\n",
    "'smooth_entro_o','smooth_entro_d','ori_cluster','dst_cluster','dist_km','community_m6',\n",
    "'mrt_km_d']\n",
    "xcol=['ori', 'dst', 'dist_km',\n",
    "       'fsize_m6_wd_pm', 'community_m6', 'mrt_km_o',\n",
    "       'entro_o', 'cycle_km_o', 'far_hdb_o', 'far_priv_o', 'far_comm_o',\n",
    "       'mrt_km_d', 'entro_d', 'cycle_km_d', 'far_hdb_d', 'far_priv_d',\n",
    "       'far_comm_d', 'smooth_entro_o', 'smooth_entro_d', 'ori_lat', 'ori_lon',\n",
    "       'dst_lat', 'dst_lon', 'has_trip', 'ori_lonal_pc1', 'ori_lonal_pc2',\n",
    "       'dst_lonal_pc1', 'dst_lonal_pc2', 'od_lonal_pc1', 'od_lonal_pc2',\n",
    "       'od_lonal_pc3', 'od_lonal_pc4','ori_cluster','dst_cluster']\n",
    "# xcolstd=['dist_km', 'mrt_km_o',\n",
    "#        'cycle_km_o', 'far_hdb_o', 'far_priv_o', 'far_comm_o',\n",
    "#        'mrt_km_d',  'cycle_km_d', 'far_hdb_d', 'far_priv_d',\n",
    "#        'far_comm_d', 'ori_lat', 'ori_lon',\n",
    "# #        'dst_lat', 'dst_lon', 'od_lonal_pc4']\n",
    "\n",
    "# for col in xcolstd:\n",
    "#     m=data[col]\n",
    "#     data[col]=(m - m.mean(axis=0)) / m.std(axis=0)\n",
    "\n",
    "def get_score(ratio,xcol,xcol1,xcol2,xcol3,ycol):\n",
    "    y=data[ycol]\n",
    "    X=data[xcol]\n",
    "\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=ratio)\n",
    "    X_train1=X_train[xcol1]\n",
    "    X_test1=X_test[xcol1]\n",
    "    model_1=RandomForestRegressor(random_state=1)\n",
    "    model_1.fit(X_train1,y_train)\n",
    "    y_pred=model_1.predict(X_test1)\n",
    "    r21=r2_score(y_pred=y_pred,y_true=y_test)\n",
    "\n",
    "    X_train2=X_train[xcol2]\n",
    "    X_test2=X_test[xcol2]\n",
    "    model_2=RandomForestRegressor(random_state=1)\n",
    "    model_2.fit(X_train2,y_train)\n",
    "    y_pred=model_2.predict(X_test2)\n",
    "    r22=r2_score(y_pred=y_pred,y_true=y_test)\n",
    "    \n",
    "    X_train3=X_train[xcol3]\n",
    "    X_test3=X_test[xcol3]\n",
    "    model_3=RandomForestRegressor(random_state=1)\n",
    "    model_3.fit(X_train3,y_train)\n",
    "    y_pred=model_3.predict(X_test3)\n",
    "    r23=r2_score(y_pred=y_pred,y_true=y_test)\n",
    "    \n",
    "    return r21,r22,r23\n",
    "\n",
    "get_score(0.3,xcol,xcol1,xcol2,xcol3,ycol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster效果远好于PCA,从下面开始做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0=pd.read_csv('lonal_entro.csv')\n",
    "data0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('pca_far.csv').set_index('ori')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg=pd.read_csv('new_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['smooth_entro_o']=data0['smooth_entro_o']\n",
    "data['smooth_entro_d']=data0['smooth_entro_d']\n",
    "data['dst_cluster']=data0['dst_cluster']\n",
    "data['ori_cluster']=data0['ori_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sg.ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  random\n",
    "sample=random.sample(list(ori),1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=list(set(ori).difference(set(sample)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train),len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_regression \n",
    "plt.style.use(\"bmh\")\n",
    "def make_mi_scores(X, y):\n",
    "    X = X.copy()\n",
    "    for colname in X.select_dtypes([\"object\", \"category\"]):\n",
    "        X[colname], _ = X[colname].factorize()\n",
    "    discrete_features = [pd.api.types.is_integer_dtype(t) for t in X.dtypes]\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features=discrete_features, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "MIX=data[['dist_km', 'fsize_m6_wd_pm',\n",
    "        'community_m6', 'mrt_km_o', 'entro_o', 'cycle_km_o',\n",
    "       'far_hdb_o', 'far_priv_o', 'far_comm_o', 'mrt_km_d', 'entro_d',\n",
    "       'cycle_km_d', 'far_hdb_d', 'far_priv_d', 'far_comm_d', 'ori_far_pc1',\n",
    "       'ori_far_pc2', 'ori_far_pc3', 'dst_far_pc2', 'od_far_pc1', 'od_far_pc2',\n",
    "       'od_far_pc3', 'dst_far_pc1', 'dst_far_pc3', 'smooth_entro_o',\n",
    "       'smooth_entro_d', 'dst_cluster', 'ori_cluster']]\n",
    "MIy=data['trip_m6_wd_pm']\n",
    "scores=make_mi_scores(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=200,figsize=(6, 6.5))\n",
    "plot_mi_scores(scores)\n",
    "plt.savefig('mi.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xcol=[ 'ori','dist_km', 'fsize_m6_wd_pm',\n",
    "        'community_m6', 'mrt_km_o', 'entro_o', 'cycle_km_o',\n",
    "       'far_hdb_o', 'far_priv_o', 'far_comm_o', 'mrt_km_d', 'entro_d',\n",
    "       'cycle_km_d', 'far_hdb_d', 'far_priv_d', 'far_comm_d', 'ori_far_pc1',\n",
    "       'ori_far_pc2', 'ori_far_pc3', 'dst_far_pc2', 'od_far_pc1', 'od_far_pc2',\n",
    "       'od_far_pc3', 'dst_far_pc1', 'dst_far_pc3', 'smooth_entro_o',\n",
    "       'smooth_entro_d', 'dst_cluster', 'ori_cluster']\n",
    "ycol='trip_m6_wd_pm'\n",
    "xcol3=[ 'dist_km','fsize_m6_wd_pm','mrt_km_o','community_m6',\n",
    "'smooth_entro_o','smooth_entro_d','ori_cluster','dst_cluster','dist_km','community_m6',\n",
    "'mrt_km_d','ori_far_pc1',\n",
    "       'ori_far_pc2','dst_far_pc1','dst_far_pc2']\n",
    "\n",
    "\n",
    "\n",
    "# X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "train_data=data.loc[train]\n",
    "test_data=data.loc[sample]\n",
    "\n",
    "\n",
    "X_train3=train_data[xcol3]\n",
    "X_test3=test_data[xcol3]\n",
    "y_train=train_data[ycol]\n",
    "y_test=test_data[ycol]\n",
    "model_3=RandomForestRegressor(max_depth=30,random_state=1,n_estimators=1000,n_jobs=-1,criterion='mse',max_features=5)\n",
    "\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import xgboost as xgb\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    " \n",
    " \n",
    "# #导入训练数据\n",
    "# traindata = pd.read_csv(\"lonal_entro.csv\")\n",
    "# traindata = traindata.set_index('ori')\n",
    "# trainlabel = traindata['trip_m6_wd_pm']\n",
    "# del traindata['trip_m6_wd_pm']\n",
    "# print(traindata.shape,trainlabel.shape)\n",
    " \n",
    " \n",
    "# #分类器使用 xgboost\n",
    "# clf1 = xgb.XGBClassifier()\n",
    " \n",
    "# #设定搜索的xgboost参数搜索范围，值搜索XGBoost的主要6个参数\n",
    "# param_dist = {\n",
    "#         'n_estimators':range(50,200,15),\n",
    "#         'max_depth':range(2,10,2),\n",
    "#         'learning_rate':np.linspace(0.01,2,20),\n",
    "#         'subsample':np.linspace(0.7,0.9,20),\n",
    "#         'colsample_bytree':np.linspace(0.5,0.98,10),\n",
    "#         'min_child_weight':range(1,9,1)\n",
    "#         }\n",
    " \n",
    "# #RandomizedSearchCV参数说明，clf1设置训练的学习器\n",
    "# #param_dist字典类型，放入参数搜索范围\n",
    "# #scoring = 'neg_log_loss'，精度评价方式设定为“neg_log_loss“\n",
    "# #n_iter=300，训练300次，数值越大，获得的参数精度越大，但是搜索时间越长\n",
    "# #n_jobs = -1，使用所有的CPU进行训练，默认为1，使用1个CPU\n",
    "\n",
    "# # rf = RandomForestRegressor()\n",
    "# grid = RandomizedSearchCV(clf1,param_dist,cv = 3,scoring = 'neg_log_loss',n_iter=300,n_jobs = -1)\n",
    " \n",
    "# #在训练集上训练\n",
    "# grid.fit(traindata.values,np.ravel(trainlabel.values))\n",
    "# #返回最优的训练器\n",
    "# best_estimator = grid.best_estimator_\n",
    "# print(best_estimator)\n",
    "# #输出最优训练器的精度\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3.fit(X_train3,y_train)\n",
    "\n",
    "y_pred0=pd.DataFrame(model_3.predict(X_test3),columns=['y_pred0'])\n",
    "y_pred0['ori']=X_test3.index\n",
    "y_pred1=y_pred0.groupby('ori')['y_pred0'].agg(['sum'])\n",
    "y_true=test_data.groupby('ori')['trip_m6_wd_pm'].agg(['sum'])\n",
    "r23=r2_score(y_pred=y_pred1,y_true=y_true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(y_pred=y_pred1,y_true=y_true)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae=mean_absolute_error(y_pred=y_pred1,y_true=y_true)\n",
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg.set_index('ori').loc[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotcol=['fsize_m6_wd_pm']\n",
    "for col in plotcol:\n",
    "\n",
    "    plt.style.use('bmh')\n",
    "    plt.figure(dpi=150)    \n",
    "    plt.title('demand_fit'+'_ori')\n",
    "    \n",
    "    plt.xlabel('X_'+'ori')\n",
    "    plt.ylabel('y_demand')\n",
    "    \n",
    "    sns.lmplot(sample,y_true,'bo',sample,y_pred1,'co',markersize=2)\n",
    "    plt.legend(['true_val','pred_val'])\n",
    "    plt.savefig('demand'+'_ori'+'.jpg')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('trip_distribution',loc='center')\n",
    "plt.figure(dpi=200)\n",
    "df.groupby('trip_m6_wd_pm')['trip_m6_wd_pm'].agg(['count']).plot()\n",
    "\n",
    "plt.savefig('trip_distribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('python36': conda)",
   "name": "python3613jvsc74a57bd0c4ba2975249f22329a2bfd4358de00082d7a2d8b97caacaf84290d52b0d66844"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
